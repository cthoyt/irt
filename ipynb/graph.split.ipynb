{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "relevant-committee",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Create an Open-World Split\n",
    "\n",
    "This notebook details how dataset splits can be created using the\n",
    "example of IRT-CDE. The algorithm to determine *concept entities* and\n",
    "the subsequent selection of *open-world* entities is described in\n",
    "Section 3 of the paper. An implementation of that algorithm can be\n",
    "found in `irt/graph/split.py:Splitter.create`. We first create a\n",
    "`split.Dataset` and then, adding textual information, a\n",
    "`text.Dataset`. These both then form an IRT dataset.\n",
    "\n",
    "First, a knowledge graph needs to be loaded. We use CoDEx and the\n",
    "loader defined in `irt/graph/loader.py`. Each loader function returns\n",
    "a `irt.graph.GraphImport` instance that is used to instantiate an\n",
    "`irt.graph.Graph`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "instrumental-orchestra",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import irt\n",
    "\n",
    "name = 'irt.cde-ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enabling-district",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "You need to have codex cloned:\n",
    "\n",
    "``` bash\n",
    "mkdir -p lib\n",
    "git clone https://github.com/tsafavi/codex lib/codex\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-resident",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a graph import\n",
    "\n",
    "from irt.graph import loader as graph_loader\n",
    "\n",
    "data_dir = irt.ENV.LIB_DIR / 'codex/data'\n",
    "\n",
    "source = graph_loader.load_codex(\n",
    "    data_dir / 'triples/codex-m/train.txt',\n",
    "    data_dir / 'triples/codex-m/valid.txt',\n",
    "    data_dir / 'triples/codex-m/test.txt',\n",
    "    f_ent2id=data_dir / 'entities/en/entities.json',\n",
    "    f_rel2id=data_dir / 'relations/en/relations.json',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-centre",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# instantiate and persist a graph instance\n",
    "\n",
    "from irt.graph import graph\n",
    "g = graph.Graph(name=name, source=source)\n",
    "\n",
    "print(str(g))\n",
    "print(g.description)\n",
    "g.save(irt.ENV.DATASET_DIR / name / 'graph')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-bishop",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Determine the relation ratio\n",
    "\n",
    "Each relation has a ratio which we use to determine concept entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-upset",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from irt.graph import split\n",
    "from tabulate import tabulate\n",
    "\n",
    "rels = split.Relation.from_graph(g)\n",
    "rels.sort(key=lambda rel: rel.ratio)\n",
    "\n",
    "\n",
    "def show_relations(rels, N: int = 10):\n",
    "    rows = [(i, r.r, r.ratio, len(r.hs), len(r.ts), r.name) for i, r in enumerate(rels, 1)]\n",
    "\n",
    "    print(f'first {N}')\n",
    "    print(tabulate(rows[:N]))\n",
    "\n",
    "\n",
    "print(f'got {len(rels)} relations')\n",
    "show_relations(rels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-roads",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_relations(g, rels):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    ax.set_title(f'Relation Distribution {name}')\n",
    "    ax.set_xlabel('Relation')\n",
    "    ax.set_ylabel('Ratio')\n",
    "\n",
    "    ax.plot(range(len(rels)), [r.ratio for r in rels], color='#333')\n",
    "\n",
    "plot_relations(g, rels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-authentication",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "After some examination we decide to apply a threshold at relation 27 and exclude some of the selected relations. Additional relations are not included (though this is possible and was applied for IRT-FB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-federation",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define the configuration\n",
    "\n",
    "cfg = split.Config(\n",
    "    # make it deterministic\n",
    "    seed=30061990,\n",
    "    # select concept entities from the first 27 relations\n",
    "    threshold=27,\n",
    "    # retain around 60% of all triples for the cw split\n",
    "    ow_split=0.6,\n",
    "    # retain around 50% of all ow triples for testing\n",
    "    ow_train_split=0.5,\n",
    "    # exclude some relations\n",
    "    excludelist=set((\n",
    "        'P551:residence',\n",
    "        'P407:language of work or name',\n",
    "        'P530:diplomatic relation',\n",
    "    )),\n",
    "    # do not include additional relations\n",
    "    includelist=set(),\n",
    ")\n",
    "\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-mineral",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# based on this configuration, a split is created\n",
    "\n",
    "from irt.common import helper\n",
    "helper.seed(cfg.seed)\n",
    "\n",
    "path = helper.path(irt.ENV.DATASET_DIR / name / 'split', create=True)\n",
    "splitter = split.Splitter(g=g, cfg=cfg, name=name, path=path)\n",
    "splitter.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-rating",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we have the raw data saved to an sqlite database\n",
    "# create the fitting loader and pass it to the text selector\n",
    "\n",
    "from irt.text import loader as text_loader\n",
    "\n",
    "database = irt.ENV.SRC_DIR / 'text' / 'cde' / 'contexts-v7-2020-12-31.db'\n",
    "loader = text_loader.SQLite(database=database)\n",
    "\n",
    "from irt.text import selector\n",
    "\n",
    "# this creates the text files in DATASET_DIR / <name> / text\n",
    "\n",
    "path = helper.path(irt.ENV.DATASET_DIR / name, create=True)\n",
    "selector.create(loader=loader, path=path, seed=cfg.seed, contexts=30, mask=True, mark=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "mathematical-culture",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6cd5adcbe2ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mirt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mirt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATASET_DIR\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Complex/scm/lavis-nlp/irt/irt/data/dataset.py\u001b[0m in \u001b[0;36m__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34mf\"{self}\\n{self.graph}\\n{self.split}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "... last 1 frames repeated, from the frame below ...\n",
      "\u001b[0;32m~/Complex/scm/lavis-nlp/irt/irt/data/dataset.py\u001b[0m in \u001b[0;36m__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34mf\"{self}\\n{self.graph}\\n{self.split}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded"
     ]
    }
   ],
   "source": [
    "ds = irt.Dataset(irt.ENV.DATASET_DIR / name)\n",
    "print(str(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "threatened-desire",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded while calling a Python object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9d838e52da14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Complex/scm/lavis-nlp/irt/irt/data/dataset.py\u001b[0m in \u001b[0;36mdescription\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mlru_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34mf\"IRT Dataset\\n{self.graph.description}\\n{self.split.description}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Complex/scm/lavis-nlp/irt/irt/data/dataset.py\u001b[0m in \u001b[0;36m__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34mf\"{self}\\n{self.graph}\\n{self.split}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "... last 1 frames repeated, from the frame below ...\n",
      "\u001b[0;32m~/Complex/scm/lavis-nlp/irt/irt/data/dataset.py\u001b[0m in \u001b[0;36m__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34mf\"{self}\\n{self.graph}\\n{self.split}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded while calling a Python object"
     ]
    }
   ],
   "source": [
    "# verbose description\n",
    "print(ds.description)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "name": "graph.split.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
